{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "table_path = Path(\"tables\")\n",
    "if not table_path.exists():\n",
    "    table_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RoBERTa Base Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>\\# Trainable Params</th>\n",
       "      <th>SST-2</th>\n",
       "      <th>MRPC</th>\n",
       "      <th>CoLA</th>\n",
       "      <th>QNLI</th>\n",
       "      <th>RTE</th>\n",
       "      <th>STS-B</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FT$^*$</td>\n",
       "      <td>125M</td>\n",
       "      <td>94.8</td>\n",
       "      <td>90.2</td>\n",
       "      <td>63.6</td>\n",
       "      <td>92.8</td>\n",
       "      <td>78.7</td>\n",
       "      <td>91.2</td>\n",
       "      <td>85.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BitFit$^*$</td>\n",
       "      <td>0.1M</td>\n",
       "      <td>93.7</td>\n",
       "      <td>92.7</td>\n",
       "      <td>62.0</td>\n",
       "      <td>91.8</td>\n",
       "      <td>81.5</td>\n",
       "      <td>90.8</td>\n",
       "      <td>85.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VeRA$^*$</td>\n",
       "      <td>0.04M</td>\n",
       "      <td>94.6±.1</td>\n",
       "      <td>89.5±.5</td>\n",
       "      <td>65.6±.8</td>\n",
       "      <td>91.8±.2</td>\n",
       "      <td>78.7±.7</td>\n",
       "      <td>90.7±.2</td>\n",
       "      <td>85.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LoRA$^*$</td>\n",
       "      <td>0.3M</td>\n",
       "      <td>95.1±.2</td>\n",
       "      <td>89.7±.7</td>\n",
       "      <td>63.4±1.2</td>\n",
       "      <td>93.3±.3</td>\n",
       "      <td>86.6±.7</td>\n",
       "      <td>91.5±.2</td>\n",
       "      <td>86.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Method \\# Trainable Params    SST-2     MRPC      CoLA     QNLI  \\\n",
       "0      FT$^*$                125M     94.8     90.2      63.6     92.8   \n",
       "1  BitFit$^*$                0.1M     93.7     92.7      62.0     91.8   \n",
       "2    VeRA$^*$               0.04M  94.6±.1  89.5±.5   65.6±.8  91.8±.2   \n",
       "3    LoRA$^*$                0.3M  95.1±.2  89.7±.7  63.4±1.2  93.3±.3   \n",
       "\n",
       "       RTE    STS-B  Average  \n",
       "0     78.7     91.2     85.2  \n",
       "1     81.5     90.8     85.4  \n",
       "2  78.7±.7  90.7±.2     85.1  \n",
       "3  86.6±.7  91.5±.2     86.6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lcccccccc}\n",
      "\\toprule\n",
      "Method & \\# Trainable Params & SST-2 & MRPC & CoLA & QNLI & RTE & STS-B & Average \\\\\n",
      "\\midrule\n",
      "FT$^*$ & \\bfseries 125M & 94.8 & 90.2 & 63.6 & 92.8 & 78.7 & 91.2 & 85.2 \\\\\n",
      "BitFit$^*$ & 0.1M & 93.7 & \\bfseries 92.7 & 62.0 & 91.8 & 81.5 & 90.8 & 85.4 \\\\\n",
      "\\bfseries VeRA$^*$ & 0.04M & 94.6\\tiny ±.1 & 89.5\\tiny ±.5 & \\bfseries 65.6\\tiny ±.8 & 91.8\\tiny ±.2 & 78.7\\tiny ±.7 & 90.7\\tiny ±.2 & 85.1 \\\\\n",
      "LoRA$^*$ & 0.3M & \\bfseries 95.1\\tiny ±.2 & 89.7\\tiny ±.7 & 63.4\\tiny ±1.2 & \\bfseries 93.3\\tiny ±.3 & \\bfseries 86.6\\tiny ±.7 & \\bfseries 91.5\\tiny ±.2 & \\bfseries 86.6 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Table :\n",
    "# Method | # params # SST-2 # MRPC # CoLA # QNLI # RTE # STS-B #\n",
    "\n",
    "tab = [\n",
    "    [\"FT$^*$\", \"125M\", 94.8, 90.2, 63.6, 92.8, 78.7, 91.2],\n",
    "    [\"BitFit$^*$\", \"0.1M\", 93.7, 92.7, 62.0, 91.8, 81.5, 90.8],\n",
    "    [\n",
    "        \"VeRA$^*$\",\n",
    "        \"0.04M\",\n",
    "        \"94.6±.1\",\n",
    "        \"89.5±.5\",\n",
    "        \"65.6±.8\",\n",
    "        \"91.8±.2\",\n",
    "        \"78.7±.7\",\n",
    "        \"90.7±.2\",\n",
    "    ],\n",
    "    [\n",
    "        \"LoRA$^*$\",\n",
    "        \"0.3M\",\n",
    "        \"95.1±.2\",\n",
    "        \"89.7±.7\",\n",
    "        \"63.4±1.2\",\n",
    "        \"93.3±.3\",\n",
    "        \"86.6±.7\",\n",
    "        \"91.5±.2\",\n",
    "    ],\n",
    "]\n",
    "\n",
    "tab = pd.DataFrame(\n",
    "    tab,\n",
    "    columns=[\n",
    "        \"Method\",\n",
    "        \"\\# Trainable Params\",\n",
    "        \"SST-2\",\n",
    "        \"MRPC\",\n",
    "        \"CoLA\",\n",
    "        \"QNLI\",\n",
    "        \"RTE\",\n",
    "        \"STS-B\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "tab[\"Average\"] = (\n",
    "    (tab.iloc[:, 2:].map(lambda x: float(x.split(\"±\")[0]) if isinstance(x, str) else x))\n",
    "    .mean(axis=1)\n",
    "    .round(1)\n",
    ")\n",
    "\n",
    "display(tab)\n",
    "\n",
    "tab_latex = (\n",
    "    tab.map(str)\n",
    "    .style.hide(level=0, axis=0)\n",
    "    .highlight_max(axis=0, props=\"font-weight:bold\")\n",
    "    .to_latex(\n",
    "        # position_float=\"centering\",\n",
    "        convert_css=True,\n",
    "        hrules=True,\n",
    "        # caption=\"Results on the GLUE benchmark for the RoBERTa-base model. Results derived from the original paper are indicated with asterisk.\",\n",
    "        # label=\"tab:glue_results_base\",\n",
    "        column_format=\"lcccccccc\",\n",
    "    )\n",
    ")\n",
    "\n",
    "tab_latex = tab_latex.replace(\"table\", \"table*\").replace(\"±\", r\"\\tiny ±\")\n",
    "with open(table_path / \"glue_results_base.tex\", \"w\") as f:\n",
    "    f.write(tab_latex)\n",
    "print(tab_latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DynaLoRA Periodic;50 scaled_multinomial;16 target_modules=qv; everything else default from the original LoRA paper\n",
    "#sst2 and qnli got interrupted but doesn't matter because the performance plateaued\n",
    "sst2:{'eval_loss': 0.29289835691452026, 'eval_accuracy': 0.9357798165137615, 'eval_runtime': 1.1564, 'eval_samples_per_second': 754.057, 'eval_steps_per_second': 47.561, 'epoch': 14.0}\n",
    "mrpc: {'eval_loss': 0.6382217407226562, 'eval_accuracy': 0.8799019607843137, 'eval_f1': 0.9126559714795008, 'eval_runtime': 0.5765, 'eval_samples_per_second': 707.693, 'eval_steps_per_second': 45.098, 'epoch': 30.0}\n",
    "cola:{'eval_loss': 0.7748498916625977, 'eval_matthews_correlation': 0.613211494270806, 'eval_runtime': 0.7249, 'eval_samples_per_second': 1438.813, 'eval_steps_per_second': 45.523, 'epoch': 80.0}\n",
    "qnli:{'eval_loss': 0.2071428894996643, 'eval_accuracy': 0.9245835621453414, 'eval_runtime': 3.9549, 'eval_samples_per_second': 1381.322, 'eval_steps_per_second': 43.237, 'epoch': 18.0}\n",
    "rte:{'eval_loss': 2.398937225341797, 'eval_accuracy': 0.7436823104693141, 'eval_runtime': 0.2486, 'eval_samples_per_second': 1114.257, 'eval_steps_per_second': 36.203, 'epoch': 80.0}\n",
    "stsb:{'eval_loss': 0.4319670796394348, 'eval_pearson': 0.9015937752451963, 'eval_spearmanr': 0.8973924327737192, 'eval_runtime': 2.0066, 'eval_samples_per_second': 747.547, 'eval_steps_per_second': 46.846, 'epoch': 60.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DnyaVera Periodic;50 scaled_multinomial;16 target_modules=qv; everything else default from the original LoRA paper\n",
    "#sst2 and qnli got interrupted but doesn't matter because the performance plateaued\n",
    "sst2: {'eval_loss': 0.20146049559116364, 'eval_accuracy': 0.930045871559633, 'eval_runtime': 1.2286, 'eval_samples_per_second': 709.758, 'eval_steps_per_second': 44.767, 'epoch': 14.0}\n",
    "mrpc: {'eval_loss': 0.35436925292015076, 'eval_accuracy': 0.8455882352941176, 'eval_f1': 0.8908145580589255, 'eval_runtime': 0.6047, 'eval_samples_per_second': 674.692, 'eval_steps_per_second': 42.995, 'epoch': 30.0}\n",
    "cola: {'eval_loss': 0.4688529074192047, 'eval_matthews_correlation': 0.5726807034874348, 'eval_runtime': 0.7509, 'eval_samples_per_second': 1388.921, 'eval_steps_per_second': 43.945, 'epoch': 80.0}\n",
    "qlni: {'eval_loss': 0.2479555308818817, 'eval_accuracy': 0.900054914881933, 'eval_runtime': 4.2944, 'eval_samples_per_second': 1272.109, 'eval_steps_per_second': 39.819, 'epoch': 16.0}\n",
    "rte: {'eval_loss': 0.6436030268669128, 'eval_accuracy': 0.7184115523465704, 'eval_runtime': 0.2626, 'eval_samples_per_second': 1054.699, 'eval_steps_per_second': 34.268, 'epoch': 80.0}\n",
    "stsb: {'eval_loss': 0.4433596134185791, 'eval_pearson': 0.8998979883307653, 'eval_spearmanr': 0.8982344018448297, 'eval_runtime': 2.082, 'eval_samples_per_second': 720.454, 'eval_steps_per_second': 45.148, 'epoch': 60.0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DynaVera Periodic;50 scaled_multinomial;16 target_modules=qv; --learning_rate 5e-03, the rest default from VeRA paper\n",
    "#sst2 and qnli got interrupted but doesn't matter because the performance plateaued\n",
    "sst2: {'eval_loss': 0.20765171945095062, 'eval_accuracy': 0.948394495412844, 'eval_runtime': 0.3514, 'eval_samples_per_second': 2481.756, 'eval_steps_per_second': 39.845, 'epoch': 55.0}\n",
    "mrpc: {'eval_loss': 0.36242952942848206, 'eval_accuracy': 0.8725490196078431, 'eval_f1': 0.9074733096085409, 'eval_runtime': 0.2077, 'eval_samples_per_second': 1964.719, 'eval_steps_per_second': 33.708, 'epoch': 30.0}\n",
    "cola: {'eval_loss': 0.6417329907417297, 'eval_matthews_correlation': 0.6509996377817916, 'eval_runtime': 0.4068, 'eval_samples_per_second': 2563.973, 'eval_steps_per_second': 41.791, 'epoch': 80.0}\n",
    "qnli: {'eval_loss': 0.20788568258285522, 'eval_accuracy': 0.9240344133260113, 'eval_runtime': 3.3208, 'eval_samples_per_second': 1645.073, 'eval_steps_per_second': 25.897, 'epoch': 22.0}\n",
    "rte: {'eval_loss': 1.5039279460906982, 'eval_accuracy': 0.7653429602888087, 'eval_runtime': 0.2725, 'eval_samples_per_second': 1016.37, 'eval_steps_per_second': 18.346, 'epoch': 160.0}\n",
    "stsb: {'eval_loss': 0.4157522916793823, 'eval_pearson': 0.9063407242521716, 'eval_spearmanr': 0.9033773221678157, 'eval_runtime': 0.6282, 'eval_samples_per_second': 2387.813, 'eval_steps_per_second': 38.205, 'epoch': 80.0}\n"
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA : Periodic;50, scaled_multinomial;20, target_modules=qkv, 60 epochs\n",
    "sst2 : {'eval_loss': 0.239357128739357, 'eval_accuracy': 0.9369266055045872, 'eval_runtime': 0.7175, 'eval_samples_per_second': 1215.352, 'eval_steps_per_second': 39.025, 'epoch': 24.0}\n",
    "mrpc : {'eval_loss': 0.7762095928192139, 'eval_accuracy': 0.8799019607843137, 'eval_f1': 0.9144851657940664, 'eval_runtime': 0.3631, 'eval_samples_per_second': 1123.625, 'eval_steps_per_second': 35.802, 'epoch': 60.0}\n",
    "cola : {'eval_loss': 0.7190002202987671, 'eval_matthews_correlation': 0.6008475155631261, 'eval_runtime': 0.8257, 'eval_samples_per_second': 1263.146, 'eval_steps_per_second': 39.965, 'epoch': 60.0}\n",
    "qnli :{'eval_loss': 0.2183120846748352, 'eval_accuracy': 0.9229361156873512, 'eval_runtime': 4.5767, 'eval_samples_per_second': 1193.642, 'eval_steps_per_second': 37.363, 'epoch': 14.0}\n",
    "rte: {'eval_loss': 1.549071192741394, 'eval_accuracy': 0.7581227436823105, 'eval_runtime': 0.2701, 'eval_samples_per_second': 1025.541, 'eval_steps_per_second': 33.321, 'epoch': 60.0}\n",
    "stsb : {'eval_loss': 0.4212930500507355, 'eval_pearson': 0.9052542545685183, 'eval_spearmanr': 0.9010987912062565, 'eval_runtime': 1.2137, 'eval_samples_per_second': 1235.874, 'eval_steps_per_second': 38.724, 'epoch': 60.0}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
